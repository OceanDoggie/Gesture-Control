#!/usr/bin/env python3
"""
å®æ—¶æ‰‹åŠ¿è¯†åˆ«æœåŠ¡ï¼ˆå¸¦æ‰“åˆ†ç³»ç»Ÿï¼‰
æ•´åˆMediapipe.pyçš„æ‰“åˆ†åŠŸèƒ½ + EMA å¹³æ»‘ + ç½®ä¿¡åº¦è®¡ç®—
æ–°å¢ï¼šlandmarks æ•°æ®ã€client_id éš”ç¦»ã€EMA ç¼“å­˜æ¸…ç†ã€debug æ—¥å¿—
"""
import sys
import json
import base64
import cv2
import mediapipe as mp
import numpy as np
import joblib
import os
import time
from collections import defaultdict

# åˆå§‹åŒ–MediaPipe Hands
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=2,
    min_detection_confidence=0.7,
    min_tracking_confidence=0.7
)

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
model = None
possible_paths = [
    'server/ml/asl_knn_model.pkl',
    'asl_knn_model.pkl',
    os.path.join(os.path.dirname(__file__), 'asl_knn_model.pkl')
]

model_loaded = False
for model_path in possible_paths:
    try:
        if os.path.exists(model_path):
            model = joblib.load(model_path)
            print(json.dumps({'type': 'status', 'message': f'âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}'}), flush=True)
            model_loaded = True
            break
    except Exception as e:
        continue

if not model_loaded:
    print(json.dumps({'type': 'warning', 'message': 'âš ï¸ æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°'}), flush=True)

# EMA å¹³æ»‘é…ç½®ï¼ˆæ”¯æŒ client_id éš”ç¦»ï¼‰
ema_conf = {}  # key: "client_id:target" -> (value, timestamp)
EMA_ALPHA = 0.35  # å¹³æ»‘ç³»æ•°
MAX_CACHE_AGE = 300  # EMA ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰= 5 åˆ†é’Ÿ
frame_count = 0  # å¸§è®¡æ•°å™¨ï¼Œç”¨äºå®šæœŸæ¸…ç†ç¼“å­˜

# Debug æ¨¡å¼å¼€å…³ï¼ˆPY_DEBUG ç¯å¢ƒå˜é‡ï¼‰
DEBUG = os.getenv("PY_DEBUG", "false").lower() == "true" or os.getenv("DEBUG", "false").lower() == "true"

def extract_landmarks(hand_landmarks):
    """æå–æ‰‹éƒ¨å…³é”®ç‚¹ç‰¹å¾ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰"""
    # æŒ‰ç…§è®­ç»ƒæ—¶çš„ç‰¹å¾é¡ºåºï¼šxåæ ‡ + yåæ ‡ + zåæ ‡
    user_vector = []
    user_vector.extend([lm.x for lm in hand_landmarks.landmark])
    user_vector.extend([lm.y for lm in hand_landmarks.landmark])
    user_vector.extend([lm.z for lm in hand_landmarks.landmark])
    return user_vector

def ema_smooth(client_id, target, value):
    """
    æŒ‡æ•°ç§»åŠ¨å¹³å‡å¹³æ»‘å‡½æ•°ï¼ˆæ”¯æŒ client_id éš”ç¦»ï¼‰
    å‚æ•°:
        client_id: å®¢æˆ·ç«¯å”¯ä¸€æ ‡è¯†
        target: ç›®æ ‡æ‰‹åŠ¿
        value: å½“å‰å¸§çš„åŸå§‹ç½®ä¿¡åº¦
    è¿”å›:
        å¹³æ»‘åçš„ç½®ä¿¡åº¦
    """
    key = f"{client_id}:{target}"
    prev_value, _ = ema_conf.get(key, (0.0, 0))
    smoothed = EMA_ALPHA * value + (1 - EMA_ALPHA) * prev_value
    ema_conf[key] = (smoothed, time.time())
    return smoothed

def check_landmarks_quality(landmarks_data, is_raw_points=False):
    """
    æ£€æµ‹å…³é”®ç‚¹è´¨é‡ï¼šåŸºäºå¹³å‡å¯è§åº¦å’Œ bbox é¢ç§¯
    å‚æ•°:
        landmarks_data: mediapipe hand_landmarks å¯¹è±¡ æˆ– åŸå§‹ç‚¹åˆ—è¡¨ [[x,y,z], ...]
        is_raw_points: æ˜¯å¦ä¸ºåŸå§‹ç‚¹åˆ—è¡¨ï¼ˆå‰ç«¯å‘æ¥çš„æ ¼å¼ï¼‰
    è¿”å›: (landmarks_ok, avg_vis, bbox_area)
    å®¹é”™åˆ¤å®šï¼šavg_vis é»˜è®¤ 1.0ï¼ˆæ—  visibility æ—¶ï¼‰ && bbox_area > 0.005ï¼ˆæ”¾å®½åˆ°è®­ç»ƒæ•°æ® 10% åˆ†ä½ï¼‰
    """
    if is_raw_points:
        # å‰ç«¯å‘æ¥çš„åŸå§‹ç‚¹åˆ—è¡¨ [[x,y,z], ...]
        landmarks = landmarks_data
        # visibility å®¹é”™ï¼šå‰ç«¯ tasks-vision ä¸è¿”å› visibilityï¼Œé»˜è®¤ä¸º 1.0
        avg_vis = 1.0
        xs = [p[0] for p in landmarks]
        ys = [p[1] for p in landmarks]
    else:
        # mediapipe çš„ hand_landmarks å¯¹è±¡
        landmarks = landmarks_data.landmark
        # è®¡ç®—å¹³å‡å¯è§åº¦ï¼ˆå®¹é”™ï¼šæ—  visibility å­—æ®µæ—¶é»˜è®¤ 1.0ï¼‰
        visibilities = [getattr(lm, 'visibility', 1.0) for lm in landmarks]
        avg_vis = sum(visibilities) / max(1, len(visibilities))
        xs = [lm.x for lm in landmarks]
        ys = [lm.y for lm in landmarks]
    
    # è®¡ç®— bbox é¢ç§¯
    bbox_w = max(xs) - min(xs)
    bbox_h = max(ys) - min(ys)
    bbox_area = bbox_w * bbox_h
    
    # æ”¾å®½åˆ¤å®šé˜ˆå€¼ï¼šbbox_area > 0.005ï¼ˆåŸæ¥ 0.01 å¤ªä¸¥æ ¼ï¼‰
    # avg_vis ä¸å†ä½œä¸ºæ‹¦æˆªæ¡ä»¶ï¼ˆtasks-vision æ— æ­¤å­—æ®µï¼‰
    landmarks_ok = (bbox_area > 0.005)
    
    return landmarks_ok, avg_vis, bbox_area

def cleanup_ema_cache():
    """
    æ¸…ç†è¿‡æœŸçš„ EMA ç¼“å­˜ï¼ˆåŸºäºæ—¶é—´ï¼‰
    æ¯ 100 å¸§è°ƒç”¨ä¸€æ¬¡ï¼Œåˆ é™¤è¶…è¿‡ MAX_CACHE_AGE ç§’æœªæ›´æ–°çš„ç¼“å­˜
    """
    now = time.time()
    expired_keys = [
        key for key, (value, timestamp) in ema_conf.items()
        if now - timestamp > MAX_CACHE_AGE
    ]
    for key in expired_keys:
        del ema_conf[key]
    
    if expired_keys and DEBUG:
        print(json.dumps({
            'type': 'debug',
            'message': f'Cleaned {len(expired_keys)} expired EMA cache entries'
        }), flush=True)

def calculate_grade(confidence):
    """
    è®¡ç®—è¯„åˆ†ç­‰çº§ï¼ˆæ¥è‡ªMediapipe.pyçš„æ‰“åˆ†ç³»ç»Ÿï¼‰
    """
    if confidence >= 0.9:
        return "A", "ä¼˜ç§€"
    elif confidence >= 0.75:
        return "B", "è‰¯å¥½"
    elif confidence >= 0.6:
        return "C", "åˆæ ¼"
    else:
        return "D", "éœ€è¦æ”¹è¿›"

def normalize_landmarks(points, mirrored=False):
    """
    å½’ä¸€åŒ– landmarksï¼ˆä¸è®­ç»ƒæ•°æ®å¯¹é½ï¼‰
    å‚æ•°:
        points: 21 ä¸ª [x, y, z] ç‚¹ï¼ˆèŒƒå›´ 0~1ï¼‰
        mirrored: æ˜¯å¦éœ€è¦é•œåƒå¯¹é½ï¼ˆå‰ç«¯ CSS é•œåƒæ—¶ä¸º Trueï¼‰
    è¿”å›:
        å½’ä¸€åŒ–åçš„ç‰¹å¾å‘é‡ï¼ˆ63 ç»´ï¼šx*21 + y*21 + z*21ï¼‰
    
    æ­¥éª¤:
    1. é•œåƒå¯¹é½ï¼šè‹¥ mirrored=Trueï¼Œx = 1 - x
    2. å±…ä¸­ï¼šä»¥æ‰‹è…•ç‚¹ï¼ˆindex 0ï¼‰ä¸ºåŸºå‡†
    3. å°ºåº¦å½’ä¸€ï¼šæŒ‰æ‰‹éƒ¨æœ€å¤§è¾¹ç•Œç¼©æ”¾
    """
    points = np.array(points, dtype=np.float32)
    
    # 1. é•œåƒå¯¹é½ï¼ˆå‰ç«¯æ˜¾ç¤ºé•œåƒæ—¶ï¼Œåæ ‡éœ€è¦ç¿»è½¬ï¼‰
    if mirrored:
        points[:, 0] = 1.0 - points[:, 0]  # x åæ ‡é•œåƒ
    
    # 2. å±…ä¸­ï¼šä»¥æ‰‹è…•ç‚¹ï¼ˆwrist, index=0ï¼‰ä¸ºåŸºå‡†
    wrist = points[0].copy()
    points = points - wrist  # å¹³ç§»åˆ°åŸç‚¹
    
    # 3. å°ºåº¦å½’ä¸€åŒ–ï¼šæŒ‰æœ€å¤§è¾¹ç•Œç¼©æ”¾åˆ°å•ä½å°ºåº¦
    xs, ys, zs = points[:, 0], points[:, 1], points[:, 2]
    max_range = max(xs.max() - xs.min(), ys.max() - ys.min(), zs.max() - zs.min())
    if max_range > 1e-6:  # é¿å…é™¤é›¶
        points = points / max_range
    
    # 4. è¿”å›ç‰¹å¾å‘é‡ï¼ˆä¸è®­ç»ƒæ—¶é¡ºåºä¸€è‡´ï¼šx*21 + y*21 + z*21ï¼‰
    feature_vector = np.concatenate([points[:, 0], points[:, 1], points[:, 2]])
    
    # Debug æ—¥å¿—ï¼šæ‰“å°å‰ 5 ä¸ªç‚¹çš„å½’ä¸€åŒ–ååæ ‡
    if DEBUG:
        print(json.dumps({
            'type': 'debug',
            'normalized_sample': {
                'point_0': [float(f'{points[0, 0]:.3f}'), float(f'{points[0, 1]:.3f}'), float(f'{points[0, 2]:.3f}')],
                'point_4': [float(f'{points[4, 0]:.3f}'), float(f'{points[4, 1]:.3f}'), float(f'{points[4, 2]:.3f}')],
                'x_range': [float(f'{xs.min():.3f}'), float(f'{xs.max():.3f}')],
                'y_range': [float(f'{ys.min():.3f}'), float(f'{ys.max():.3f}')],
            }
        }), flush=True)
    
    return feature_vector.tolist()

def process_landmarks_input(message):
    """
    å¤„ç†å‰ç«¯å‘æ¥çš„ landmarks æ¶ˆæ¯ï¼ˆå¸¦é•œåƒ/å•ä½ä¸Šä¸‹æ–‡ï¼‰
    å‚æ•°:
        message: {
            type: 'process_landmarks',
            client_id: str,
            points: [[x, y, z], ...],  # 21 ä¸ªç‚¹
            image: { width, height, unit: 'norm01' },
            mirrored: bool,
            target_gesture: str,
            ts: int
        }
    è¿”å›:
        ç¬¦åˆæ–°åè®®çš„ JSON å¯¹è±¡
    """
    global frame_count
    start_time = time.time()
    
    try:
        client_id = message.get('client_id', '')
        points = message.get('points', [])
        image_info = message.get('image', {})
        mirrored = message.get('mirrored', False)
        target_gesture = message.get('target_gesture', '')
        
        # éªŒè¯è¾“å…¥
        if len(points) != 21:
            return {'ok': False, 'error': f'Invalid landmarks count: {len(points)} (expected 21)'}
        
        # å•ä½å¯¹é½æ£€æŸ¥ï¼ˆç¡®ä¿æ˜¯ norm01ï¼‰
        unit = image_info.get('unit', 'norm01')
        if unit != 'norm01':
            return {'ok': False, 'error': f'Unsupported unit: {unit} (expected norm01)'}
        
        # æ£€æŸ¥å…³é”®ç‚¹è´¨é‡ï¼ˆä½¿ç”¨åŸå§‹ç‚¹æ ¼å¼ï¼‰
        landmarks_ok, avg_vis, bbox_area = check_landmarks_quality(points, is_raw_points=True)
        
        # Debug æ—¥å¿—ï¼šæ‰“å°è´¨é‡æŒ‡æ ‡
        if DEBUG:
            print(json.dumps({
                'type': 'debug',
                'quality_check': {
                    'avg_vis': round(avg_vis, 3),
                    'bbox_area': round(bbox_area, 4),
                    'landmarks_ok': landmarks_ok,
                    'mirrored': mirrored,
                }
            }), flush=True)
        
        # å®šæœŸæ¸…ç† EMA ç¼“å­˜
        frame_count += 1
        if frame_count % 100 == 0:
            cleanup_ema_cache()
        
        # å¦‚æœè´¨é‡ä¸ä½³ï¼Œè¿”å›ä½†ä¸æ‹¦æˆªï¼ˆä»…æ ‡è®°ï¼‰
        inference_time_ms = (time.time() - start_time) * 1000
        
        # å½’ä¸€åŒ– landmarksï¼ˆé•œåƒå¯¹é½ + å±…ä¸­ + å°ºåº¦å½’ä¸€ï¼‰
        user_vector = normalize_landmarks(points, mirrored)
        
        # é¢„æµ‹æ‰‹åŠ¿
        predicted_label = None
        raw_confidence = 0.0
        probs = None
        
        if model is not None:
            try:
                predicted_label = model.predict([user_vector])[0]
                probs = model.predict_proba([user_vector])[0]
                raw_confidence = float(max(probs))
            except Exception as e:
                print(json.dumps({'type': 'error', 'message': f'æ¨¡å‹æ¨ç†é”™è¯¯: {str(e)}'}), flush=True)
                predicted_label = 'Error'
                raw_confidence = 0.0
        else:
            # æ¨¡å‹æœªåŠ è½½
            predicted_label = 'A'
            raw_confidence = 0.75
        
        # è®¡ç®—æ¨ç†è€—æ—¶
        inference_time_ms = (time.time() - start_time) * 1000
        
        # Debug æ—¥å¿—ï¼šæ‰“å°é¢„æµ‹ç»“æœå’Œæ¦‚ç‡åˆ†å¸ƒ
        if DEBUG and probs is not None and model is not None:
            top3_idx = np.argsort(probs)[-3:][::-1]
            classes = model.classes_
            top3 = [(classes[i], round(float(probs[i]), 3)) for i in top3_idx]
            print(json.dumps({
                'type': 'debug',
                'prediction': {
                    'predicted': predicted_label,
                    'confidence': round(raw_confidence, 3),
                    'top3': top3,
                    'target': target_gesture,
                }
            }), flush=True)
        
        # æ€§èƒ½æ—¥å¿—ï¼ˆæ¯å¸§æ‰“å°ï¼‰
        print(json.dumps({
            'type': 'perf',
            'avg_vis': round(avg_vis, 3),
            'bbox_area': round(bbox_area, 4),
            'landmarks_ok': landmarks_ok,
            'predicted': predicted_label,
            'target': target_gesture,
            'confidence': round(raw_confidence, 3),
            'inference_ms': round(inference_time_ms, 2)
        }), flush=True)
        
        # è®¡ç®—å¾—åˆ†ï¼ˆä¸ç›®æ ‡æ‰‹åŠ¿åŒ¹é…æ—¶ = confidence * 100ï¼Œå¦åˆ™è¾ƒä½åˆ†ï¼‰
        score = 0.0
        if target_gesture and predicted_label == target_gesture:
            score = raw_confidence * 100
        elif target_gesture:
            score = max(0, raw_confidence * 30)  # é”™è¯¯æ‰‹åŠ¿ç»™äºˆä½åˆ†
        else:
            score = raw_confidence * 100  # æ— ç›®æ ‡æ—¶æŒ‰ç½®ä¿¡åº¦ç»™åˆ†
        
        # è¿”å›ç»“æœ
        return {
            'ok': True,
            'data': {
                'type': 'gesture_result',
                'client_id': client_id,
                'hands_detected': True,
                'target': target_gesture,
                'predicted': predicted_label,
                'confidence': float(raw_confidence),
                'score': round(score, 2),
                'landmarks_ok': landmarks_ok,
                'landmarks': [{'x': float(p[0]), 'y': float(p[1]), 'visibility': 1.0} for p in points],
                'server_ts': int(time.time() * 1000),
                'inference_ms': round(inference_time_ms, 2)
            }
        }
        
    except Exception as e:
        return {'ok': False, 'error': f'å¤„ç† landmarks é”™è¯¯: {str(e)}'}


def process_frame(frame_data, target_gesture="", client_id=""):
    """
    å¤„ç†è§†é¢‘å¸§å¹¶è¿”å›è¯†åˆ«ç»“æœï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼šå»æ‰é™æƒï¼Œä¿ç•™åŸå§‹confidenceï¼‰
    å‚æ•°:
        frame_data: base64 ç¼–ç çš„å›¾åƒæ•°æ®
        target_gesture: ç›®æ ‡æ‰‹åŠ¿ï¼ˆç”¨äºè¯„åˆ†ï¼‰
        client_id: å®¢æˆ·ç«¯å”¯ä¸€æ ‡è¯†ï¼ˆç”¨äº EMA éš”ç¦»ï¼‰
    è¿”å›:
        ç¬¦åˆæ–°åè®®çš„ JSON å¯¹è±¡
    """
    global frame_count
    start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´ï¼Œç”¨äºè®¡ç®—æ¨ç†è€—æ—¶
    
    try:
        # è§£ç base64å›¾åƒ
        image_data = base64.b64decode(frame_data)
        nparr = np.frombuffer(image_data, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if frame is None:
            return {'ok': False, 'error': 'æ— æ³•è§£ç å›¾åƒ'}
        
        # è½¬æ¢ä¸ºRGB
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # ä½¿ç”¨MediaPipeå¤„ç†å¸§
        results = hands.process(rgb_frame)
        
        # å®šæœŸæ¸…ç† EMA ç¼“å­˜ï¼ˆæ¯ 100 å¸§ï¼‰
        frame_count += 1
        if frame_count % 100 == 0:
            cleanup_ema_cache()
        
        # å¦‚æœæœªæ£€æµ‹åˆ°æ‰‹éƒ¨ï¼ˆæ·»åŠ  server_ts å’Œ inference_msï¼‰
        inference_time_ms = (time.time() - start_time) * 1000
        if not results.multi_hand_landmarks:
            return {
                'ok': True,
                'data': {
                    'type': 'gesture_result',
                    'client_id': client_id,
                    'hands_detected': False,
                    'target': target_gesture,
                    'predicted': None,
                    'confidence': 0.0,
                    'landmarks_ok': False,
                    'landmarks': [],
                    'server_ts': int(time.time() * 1000),  # æœåŠ¡å™¨æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
                    'inference_ms': round(inference_time_ms, 2)  # æ¨ç†è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
                }
            }
        
        # æ£€æµ‹åˆ°æ‰‹éƒ¨ - å¤„ç†ç¬¬ä¸€ä¸ªæ‰‹åŠ¿ï¼ˆä¸»æ‰‹ï¼‰
        hand_landmarks = results.multi_hand_landmarks[0]
        
        # æ£€æŸ¥å…³é”®ç‚¹è´¨é‡ï¼ˆè¿”å› landmarks_ok, avg_vis, bbox_areaï¼‰
        landmarks_ok, avg_vis, bbox_area = check_landmarks_quality(hand_landmarks)
        
        # æå–å…³é”®ç‚¹æ•°æ®ï¼ˆç”¨äºå‰ç«¯ç»˜åˆ¶ï¼‰
        landmarks = [
            {
                'x': float(lm.x),
                'y': float(lm.y),
                'visibility': float(getattr(lm, 'visibility', 1.0))
            }
            for lm in hand_landmarks.landmark
        ]
        
        # æå–å…³é”®ç‚¹ç‰¹å¾ï¼ˆç”¨äºæ¨¡å‹é¢„æµ‹ï¼‰
        user_vector = extract_landmarks(hand_landmarks)
        
        # é¢„æµ‹æ‰‹åŠ¿
        predicted_label = None
        raw_confidence = 0.0
        probs = None
        
        if model is not None:
            try:
                # ä½¿ç”¨ KNN æ¨¡å‹é¢„æµ‹
                predicted_label = model.predict([user_vector])[0]
                probs = model.predict_proba([user_vector])[0]
                raw_confidence = float(max(probs))
            except Exception as e:
                print(json.dumps({'type': 'error', 'message': f'æ¨¡å‹æ¨ç†é”™è¯¯: {str(e)}'}), flush=True)
                predicted_label = 'Error'
                raw_confidence = 0.0
        else:
            # æ¨¡å‹æœªåŠ è½½æ—¶çš„æ¨¡æ‹Ÿæ•°æ®
            predicted_label = 'A'
            raw_confidence = 0.75
        
        # è®¡ç®—æ¨ç†è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
        inference_time_ms = (time.time() - start_time) * 1000
        
        # æ‰“å°è´¨é‡æŒ‡æ ‡å’Œæ¨ç†è€—æ—¶ï¼ˆæ¯å¸§éƒ½æ‰“å°ï¼Œç”¨äºæ€§èƒ½ç›‘æ§ï¼‰
        print(json.dumps({
            'type': 'perf',
            'avg_vis': round(avg_vis, 3),
            'bbox_area': round(bbox_area, 4),
            'landmarks_ok': landmarks_ok,
            'inference_ms': round(inference_time_ms, 2)
        }), flush=True)
        
        # Debug æ—¥å¿—ï¼šæ‰“å°æ¦‚ç‡åˆ†å¸ƒï¼ˆä»…åœ¨ DEBUG æ¨¡å¼ä¸‹ï¼‰
        if DEBUG and probs is not None and model is not None:
            # è·å– top-3 æ¦‚ç‡
            top3_idx = np.argsort(probs)[-3:][::-1]
            classes = model.classes_
            top3 = [(classes[i], round(float(probs[i]), 3)) for i in top3_idx]
            print(json.dumps({
                'type': 'debug',
                'top3_probs': top3
            }), flush=True)
        
        # âš ï¸ æ€§èƒ½ä¼˜åŒ–ï¼šå»æ‰è´¨é‡é™æƒå’Œé”™ç±»é™æƒï¼Œä¿ç•™åŸå§‹ confidence
        # ç›´æ¥ä½¿ç”¨åŸå§‹ confidenceï¼Œç”¨äº A/B æµ‹è¯•
        final_confidence = raw_confidence
        
        # è¿”å›æ–°åè®®æ ¼å¼ï¼ˆæ·»åŠ  server_ts å’Œ inference_msï¼‰
        return {
            'ok': True,
            'data': {
                'type': 'gesture_result',
                'client_id': client_id,
                'hands_detected': True,
                'target': target_gesture,
                'predicted': predicted_label,
                'confidence': float(final_confidence),  # åŸå§‹ confidenceï¼Œä¸å†é™æƒ
                'landmarks_ok': landmarks_ok,
                'landmarks': landmarks,
                'server_ts': int(time.time() * 1000),  # æœåŠ¡å™¨æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
                'inference_ms': round(inference_time_ms, 2)  # æ¨ç†è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
            }
        }
        
    except Exception as e:
        return {'ok': False, 'error': f'å¤„ç†å¸§é”™è¯¯: {str(e)}'}


# ä¸»å¾ªç¯ - ä»æ ‡å‡†è¾“å…¥è¯»å–æ¶ˆæ¯
def main():
    print(json.dumps({'type': 'ready', 'message': 'âœ… å¸¦è¯„åˆ†ç³»ç»Ÿçš„æ‰‹åŠ¿è¯†åˆ«æœåŠ¡å·²å¯åŠ¨ï¼ˆæ”¯æŒ landmarks è¾“å…¥ï¼‰'}), flush=True)
    if DEBUG:
        print(json.dumps({'type': 'debug', 'message': 'ğŸ”§ Debug æ¨¡å¼å·²å¯ç”¨ï¼ˆPY_DEBUG=1ï¼‰'}), flush=True)
    
    while True:
        try:
            line = sys.stdin.readline()
            if not line:
                break
            
            message = json.loads(line.strip())
            msg_type = message.get('type')
            
            if msg_type == 'process_landmarks':
                # å¤„ç†å‰ç«¯å‘æ¥çš„ landmarksï¼ˆæ–°è·¯å¾„ï¼šæ€§èƒ½æ›´ä¼˜ï¼Œæ— éœ€é‡å¤æ£€æµ‹ï¼‰
                result = process_landmarks_input(message)
                print(json.dumps(result), flush=True)
            
            elif msg_type == 'process_frame':
                # å¤„ç†å›¾åƒå¸§ï¼ˆæ—§è·¯å¾„ï¼šå…¼å®¹ä¿ç•™ï¼‰
                frame_data = message.get('frame') or message.get('frame_data')
                target_gesture = message.get('target_gesture', '')
                client_id = message.get('client_id', '')
                
                if frame_data:
                    result = process_frame(frame_data, target_gesture, client_id)
                    print(json.dumps(result), flush=True)
            
            elif msg_type == 'ping':
                print(json.dumps({'type': 'pong', 'status': 'ok'}), flush=True)
                
        except Exception as e:
            print(json.dumps({'type': 'error', 'message': str(e)}), flush=True)

if __name__ == '__main__':
    main()


